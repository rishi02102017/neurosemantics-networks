# ğŸ” Deep Sentiment Analysis with FFNN & LSTM (PyTorch + spaCy)

<p align="center">
  <img src="SA.jpg" alt="SA" width="500"/>
</p>


A robust and extensible sentiment classification pipeline using **Feed-Forward Neural Networks (FFNN)** and **Recurrent Neural Networks (LSTM)** for both **binary** and **multi-class sentiment analysis**. This project leverages `PyTorch`, `spaCy`, and `scikit-learn` and evaluates performance on real-world datasets: **IMDB**, **Sentiment140**, and **Twitter**.

---

## ğŸš€ Features

- âœ¨ Tokenization with `spaCy` + custom vocabulary builder
- ğŸ§  FFNN with averaged embeddings and dual hidden layers
- ğŸ” LSTM-based classifier with final hidden state for classification
- ğŸ§¾ Supports both binary (IMDB, Sentiment140) and multi-class (Twitter) tasks
- ğŸ“Š Logs train/dev metrics: accuracy, loss, precision, recall, F1
- ğŸ“ˆ Visualizations for training curves (Loss, Accuracy, F1)
- ğŸ” Sample inference with decoded input sentences

---

## ğŸ§  Tech Stack

| Component | Technology |
|----------|------------|
| Language | Python 3.x |
| Framework | PyTorch |
| Tokenizer | spaCy (`en_core_web_sm`) |
| Metrics | scikit-learn |
| Plotting | Matplotlib |
| DataLoaders | PyTorch native |
| Optional | CUDA/GPU support |

---

## ğŸ“ Datasets

| Dataset | Type | Labels |
|--------|------|--------|
| [IMDB](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) | Binary | Positive / Negative |
| [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140) | Binary | Positive / Negative |
| [Twitter Dataset](https://github.com/datasets/sentiment-analysis/blob/master/twitter_training.csv) | Multi-class | Positive / Negative / Neutral |

---

## ğŸ“¦ Installation

```bash
# Clone the repo
git clone https://github.com/your-username/deep-sentiment-nlu.git
cd deep-sentiment-nlu

# Install required packages
pip install -r requirements.txt

# Download spaCy model
python -m spacy download en_core_web_sm
```

---

## ğŸ§ª How to Run

Run the full multi-dataset sentiment classification pipeline using:

```bash
jupyter notebook Codebook.ipynb
```

Inside the notebook, you can toggle between IMDB, Sentiment140, and Twitter sections using provided cell headers and execute the full training + evaluation + inference workflows.

---

## ğŸ—ï¸ Architecture Overview

### ğŸ”¹ Feed-Forward Neural Network (FFNN)
```
Input â†’ Embedding Layer â†’ Avg Pooling â†’ Linear(300â†’256) â†’ ReLU â†’ Linear(256â†’128) â†’ ReLU â†’ Linear(128â†’Output)
```

### ğŸ”¹ LSTM Network
```
Input â†’ Embedding â†’ LSTM(300â†’256) â†’ Final Hidden State â†’ Linear(256â†’Output)
```

> Output layer:  
> - Binary â†’ 1 unit with BCEWithLogitsLoss  
> - Multi-Class â†’ N units with CrossEntropyLoss

---

## ğŸ“Š Evaluation Metrics

- Accuracy
- Precision
- Recall
- F1 Score
- Plots: Loss vs Epochs, Accuracy vs Epochs, F1 Score

All results are saved/logged after each epoch for train/dev.

---

## ğŸ“· Sample Output

```
Input Sentence: this movie was absolutely wonderful , i loved every part
True Label: Positive
Predicted Label: Positive
Probability: 0.9672
```

---

## ğŸ“Œ Project Structure

```
.
â”œâ”€â”€ Codebook.ipynb              # Main notebook with all training/evaluation
â”œâ”€â”€ data/                       # Preprocessed or raw dataset files
â”œâ”€â”€ plots/                      # Training visualizations
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§  Future Improvements

- Add attention mechanism to LSTM
- Use pre-trained embeddings (GloVe/FastText)
- Enable Transformer-based comparison (BERT)
- Improve handling of emoji/emoticons in tweets

---

## ğŸ‘¨â€ğŸ’» Authors

- Jyotishman Das ([@rishi02102017](https://github.com/rishi02102017))
- Denzel Lenshanglen Lupheng
- Suvadip Chakraborty
- Mehul Sah

---

## ğŸ“œ License

MIT License

---

## â­ï¸ Show your support

If you found this project useful or inspiring:
- Leave a â­ï¸ on GitHub
- Fork it and build your own sentiment tools!

---
